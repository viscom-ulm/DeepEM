<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="DEEP-EM TOOLBOX" />
    <meta property="og:description"
        content="Unlock the power of Deep Learning in Electron Microscopy with the DEEP-EM TOOLBOX standardized workflows for EM image analysis." />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="DEEP-EM TOOLBOX">
    <meta name="twitter:description"
        content="Unlock the power of Deep Learning in Electron Microscopy with the DEEP-EM TOOLBOX standardized workflows for EM image analysis.">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Deep Learning, Electron Microscopy, Data Analysis, Data Interpretation, Toolbox">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>DEEP-EM TOOLBOX</title>
    <link rel="icon" type="image/x-icon" href="static/images/icon.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    <style>
        .hidden {
            display: none;
        }

        .button-55 {
            align-self: center;
            background-color: #fff;
            background-image: none;
            background-position: 0 90%;
            background-repeat: repeat no-repeat;
            background-size: 4px 3px;
            border-radius: 15px 225px 255px 15px 15px 255px 225px 15px;
            border-style: solid;
            border-width: 2px;
            box-shadow: rgba(0, 0, 0, .2) 15px 28px 25px -18px;
            box-sizing: border-box;
            color: #41403e;
            cursor: pointer;
            display: inline-block;
            font-family: Neucha, sans-serif;
            font-size: 1rem;
            line-height: 23px;
            outline: none;
            padding: .75rem;
            text-decoration: none;
            transition: all 235ms ease-in-out;
            border-bottom-left-radius: 15px 255px;
            border-bottom-right-radius: 225px 15px;
            border-top-left-radius: 255px 15px;
            border-top-right-radius: 15px 225px;
            user-select: none;
            -webkit-user-select: none;
            touch-action: manipulation;
        }

        .button-55:hover {
            box-shadow: rgba(0, 0, 0, .3) 2px 8px 8px -5px;
            transform: translate3d(0, 2px, 0);
        }

        .button-55:focus {
            box-shadow: rgba(0, 0, 0, .3) 2px 8px 4px -6px;
        }

        .green-background {
            background-color: #dde9afff;
            /* Green background */
            padding: 20px;
            /* Padding inside the element */
            border-radius: 10px;
            /* Rounded corners */
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            /* Subtle shadow for depth */
            font-size: 16px;
            /* Font size */
            margin: 20px 0;
            /* Margin outside the element */
        }

        .red-background {
            background-color: #ffaaaaff;
            /* Green background */
            padding: 20px;
            /* Padding inside the element */
            border-radius: 10px;
            /* Rounded corners */
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            /* Subtle shadow for depth */
            font-size: 16px;
            /* Font size */
            margin: 20px 0;
            /* Margin outside the element */
        }

        .orange-background {
            background-color: #ffb380ff;
            /* Green background */
            padding: 20px;
            /* Padding inside the element */
            border-radius: 10px;
            /* Rounded corners */
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            /* Subtle shadow for depth */
            font-size: 16px;
            /* Font size */
            margin: 20px 0;
            /* Margin outside the element */
        }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        function toggleVisibility(id_content, id_button) {
            var content = document.getElementById(id_content);
            var btn = document.getElementById(id_button);


            if (content.classList.contains('hidden')) {
                content.classList.remove('hidden');
                btn.innerHTML = "Show Less"
            } else {
                content.classList.add('hidden');
                btn.innerHTML = "Show More"

            }
        }

    </script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <!--<img src="static/images/icon.png"
                            alt="Schematic showing 3 differnt types of task applicable for deep learning. (image to values, image to image & 2D to 3D)" />
                        -->
                        <h1 class="title is-1 publication-title">Image to Value(s)</h1>
                        <!--Add use case category (one of: Image to Value(s), Image to Image, 2D to 3D)-->
                        <h2 class="title is-1 publication-title">Explainable Virus Quantification</h2>
                        <!-- Add title of the use case-->
                        <div class="is-size-5 publication-authors">
                            <!-- authors -->
                            <span class="author-block">
                                <a href="https://viscom.uni-ulm.de/members/hannah-kniesel/" target="_blank">Hannah
                                    Kniesel</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://viscom.uni-ulm.de/members/tristan-payer/" target="_blank">Tristan
                                    Payer</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://viscom.uni-ulm.de/members/poonam/" target="_blank">Poonam
                                    Poonam</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="" target="_blank">Tim Bergner</a><sup>2</sup>,
                            </span>

                            <span class="author-block">
                                <a href="https://phermosilla.github.io/" target="_blank">Pedro
                                    Hermosilla</a><sup>3</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://viscom.uni-ulm.de/members/timo-ropinski/" target="_blank">Timo
                                    Ropinski</a><sup>1</sup>,
                            </span>

                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Visual Computing Group, Ulm
                                University<br><sup>2</sup>Central
                                Facility Electron Microscopy, Ulm Univesity<br><sup>3</sup>Computer Vision Lab, TU
                                Vienna</span>
                            <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                        </div>


                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Arxiv PDF link 
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                -->

                                <!-- Supplementary PDF link 
                                    <span class="link-block">
                                    <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Supplementary</span>
                                    </a>
                                </span>-->

                                <!-- Github link 
                                <span class="link-block">
                                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                    <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                                </span> -->

                                <!-- ArXiv abstract Link 
                                <span class="link-block">
                                <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                                class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                </span>
                                <span>arXiv</span>
                                </a>
                                </span>-->

                                <span class="link-block">
                                    <a href="https:/Link to Notebook" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span>notebook</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Teaser image
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <img src="static/images/tasks.png" alt="Schematic showing 3 differnt types of task applicable for deep learning. (image to values, image to image & 2D to 3D)" />
      <h2 class="subtitle has-text-centered">We propose to categorize tasks within the area of EM data analysis into Image to Value(s), Image to Image and 2D to 3D. We do so, based on their specific requirements for implementing a deep learning workflow. For more details, please see our paper.</h2>
    </div>
  </div>
</section>
End teaser image -->




    <!-- Motivation -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="content has-text-justified">
                        <p>
                            Within this image-to-value(s) tasks, we are developing a regression model to quantify HCMV
                            capsids
                            and their
                            maturation stages during secondary envelopment in TEM images.
                            Secondary envelopment of HCMV is the process by which viral capsids acquire a final envelope
                            by budding into
                            cytoplasmic vesicles, a step essential for the production
                            of infectious progeny [1]. During this process, different maturation stages - naked, budding
                            or enveloped
                            capsids - can be observed in TEM images [2].
                            Quantifying these stages and comparing wild-type viruses with mutants that have defects in
                            secondary
                            envelopment can provide valuable insights into the proteins involved
                            and their role in this critical process [2,3,4].
                            In our notebook we aim to detect the number of naked, budding and enveloped virus particles
                            within an input
                            image.
                            We use pre-trained model weights to avoid over-fitting on the training data provided. We
                            also focus on
                            additional explanatory techniques (GradCAM [5]) to make the model more trustworthy, reliable
                            and easier to
                            detect incorrect predictions.
                        </p>

                        <p><i>[1] Mettenleiter, Thomas C. "Budding events in herpesvirus morphogenesis." Virus research
                                106.2 (2004):
                                167-180.</i></p>
                        <p><i>[2] Read, Clarissa, et al. "Regulation of human cytomegalovirus secondary envelopment by a
                                C-terminal
                                tetralysine motif in pUL71." Journal of Virology 93.13 (2019): 10-1128.</i></p>
                        <p><i>[3] Cappadona, Ilaria, et al. "Human cytomegalovirus pUL47 modulates tegumentation and
                                capsid accumulation
                                at the viral assembly complex." Journal of virology 89.14 (2015): 7314-7328.</i></p>
                        <p><i>[4] Read, Clarissa, Paul Walther, and Jens von Einem. "Quantitative electron microscopy to
                                study HCMV
                                morphogenesis." Human Cytomegaloviruses: Methods and Protocols (2021): 265-289.</i></p>
                        <p><i>[5] Selvaraju, Ramprasaath R., et al. "Grad-cam: Visual explanations from deep networks
                                via gradient-based
                                localization." Proceedings of the IEEE international conference on computer vision.
                                2017.</i></p>

                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End Motivation -->



    <!--DEEP-EM TOOLBOX Workflow -->
    <section class="section hero">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">DEEP-EM TOOLBOX: Workflow</h2>
            <div class="content has-text-justified">
                <figure>
                    <img src="static/images/Teaser-ensemble.png" alt="Depiction of ensemble model">
                    <figcaption id="fig:teaser-ensemble">
                        Figure B: For the segmentation of cellular structures we follow [1] and train a so called
                        "ensemble" model.
                        An ensemble model is a set of models which are used to make multiple predictions for the same
                        input data.
                        The predictions are then combined to retrieve a more robust prediction.
                    </figcaption>
                </figure>

                <div class="orange-background">
                    <h3>Task</h3>
                    <p>
                        For developing DL solutions for complex datasets, such as EM images, it is essential to grasp
                        both the
                        inherent characteristics of the data and the specific tasks that need to be addressed. This
                        section will
                        outline the necessary steps for defining tasks and architectures, providing a comprehensive
                        foundation
                        for effectively applying deep learning techniques to EM image analysis.
                    </p>

                    <button id="togglebtn-task-model" class="button-55"
                        onclick="toggleVisibility('content-task-model', 'togglebtn-task-model')">Show More</button>
                    <div id="content-task-model" class="hidden">
                        <p></p>
                        <h4>Definition</h4>
                        <h4>Architecture</h4>
                    </div>

                </div>
                <div class="green-background">
                    <h3>Data</h3>
                    <p>
                        Even though it is well known that large dataset sizes can drastically improve the performance of
                        DL
                        models, more data does not always equate to better model performance. High-quality data is
                        essential
                        for deriving meaningful correlations between inputs and outputs, providing a strong learning
                        signal.
                        Models must also be robust against artifacts in EM data and generalize across different sampling
                        methods, detectors, and microscopes. Ensuring balanced occurrence and variance within datasets
                        is
                        crucial. Achieving optimal model performance requires balancing data quality, variance,
                        robustness,
                        and dataset size. This is vital because a trained model functions as a black box, making it
                        difficult to
                        correct biases or errors later.
                    </p>
                    <button id="togglebtn-data" class="button-55"
                        onclick="toggleVisibility('content-data', 'togglebtn-data')">Show More</button>
                    <div id="content-data" class="hidden">
                        <p></p>
                        <h4>Acquisition</h4>
                        <h4>Annotation</h4>
                        <h4>Preprocessing</h4>
                    </div>

                </div>
                <div class="red-background">
                    <h3> Model</h3>
                    <p>
                        Model training is the process of teaching a DL model to recognize patterns in data by adjusting
                        its
                        parameters to minimize prediction errors. Model evaluation assesses the trained model’s
                        performance
                        on unseen data to determine its effectiveness and generalization capabilities, ensuring that it
                        can
                        accurately predict outcomes in real-world scenarios.
                    </p>
                    <button id="togglebtn-model" class="button-55"
                        onclick="toggleVisibility('content-model', 'togglebtn-model')">Show More</button>
                    <div id="content-model" class="hidden">
                        <p></p>
                        <h4>Training</h4>
                        <h4>Evaluation</h4>
                    </div>

                </div>

            </div>
        </div>
    </section>
    <!--End DEEP-EM TOOLBOX Workflow-->




    <!--Use your own data -->
    <section class="section hero is-light">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">Use Your Own Data</h2>
            <div class="content has-text-justified">
                <p>Here we explain how you need to preprocess your data to apply the model. </p>
                <p>Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut
                    labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores
                    et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.
                    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut
                    labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores
                    et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.</p>
                <p></p>
            </div>
        </div>
    </section>
    <!--End use your own data  -->



    <!--Links -->
    <section class="section hero">
        <div class="container is-max-desktop content">
            <h2 class="title is-3">Contact</h2>

            <div class="content has-text-justified">
                <p>If you have any questions regarding this use case, please do not hesitate to contact <a
                        href="TODO">Tristan Payer</a></p> <!--Add contact info here-->
            </div>
        </div>
    </section>
    <!--End Links  -->



    <!--BibTex citation -->
    <section class="section is-light" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>BibTex Code Here</code></pre>
        </div>
    </section>
    <!--End BibTex citation -->

    <!-- Footer  -->
    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                            You are free to borrow the of this website, we just ask that you link back to this page in
                            the footer.
                            <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- End footer -->

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>